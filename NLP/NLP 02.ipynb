{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59942ccf",
   "metadata": {},
   "source": [
    "# Bag-of-Words Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf586ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "\"I love machine learning\",\n",
    "\"Machine learning is fascinating\",\n",
    "\"I love programming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7e50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Count Vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert to array and normalize\n",
    "word_counts = X.toarray()\n",
    "normalized_counts = word_counts / np.sum(word_counts, axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31cd5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word counts:\n",
      " [[0 0 1 1 1 0]\n",
      " [1 1 1 0 1 0]\n",
      " [0 0 0 1 0 1]]\n",
      "Normalized word counts:\n",
      " [[0.         0.         0.33333333 0.33333333 0.33333333 0.        ]\n",
      " [0.25       0.25       0.25       0.         0.25       0.        ]\n",
      " [0.         0.         0.         0.5        0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word counts:\\n\", word_counts)\n",
    "print(\"Normalized word counts:\\n\", normalized_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3a612",
   "metadata": {},
   "source": [
    "# TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54b3050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e4faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      " [[0.         0.         0.57735027 0.57735027 0.57735027 0.        ]\n",
      " [0.5628291  0.5628291  0.42804604 0.         0.42804604 0.        ]\n",
      " [0.         0.         0.         0.60534851 0.         0.79596054]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30691315",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa891e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Sample corpus\n",
    "corpus = [\n",
    "\"I love machine learning\",\n",
    "\"Machine learning is fascinating\",\n",
    "\"I love programming\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d0efb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenize sentences\n",
    "tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3d21b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = Word2Vec(tokenized_corpus, vector_size=100, window=5,\n",
    "min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "057ebc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embedding for 'machine': [-8.6196875e-03  3.6657380e-03  5.1898835e-03  5.7419385e-03\n",
      "  7.4669183e-03 -6.1676754e-03  1.1056137e-03  6.0472824e-03\n",
      " -2.8400505e-03 -6.1735227e-03 -4.1022300e-04 -8.3689485e-03\n",
      " -5.6000124e-03  7.1045388e-03  3.3525396e-03  7.2256695e-03\n",
      "  6.8002474e-03  7.5307419e-03 -3.7891543e-03 -5.6180597e-04\n",
      "  2.3483764e-03 -4.5190323e-03  8.3887316e-03 -9.8581640e-03\n",
      "  6.7646410e-03  2.9144168e-03 -4.9328315e-03  4.3981876e-03\n",
      " -1.7395747e-03  6.7113843e-03  9.9648498e-03 -4.3624435e-03\n",
      " -5.9933780e-04 -5.6956373e-03  3.8508223e-03  2.7866268e-03\n",
      "  6.8910765e-03  6.1010956e-03  9.5384968e-03  9.2734173e-03\n",
      "  7.8980681e-03 -6.9895042e-03 -9.1558648e-03 -3.5575271e-04\n",
      " -3.0998408e-03  7.8943167e-03  5.9385742e-03 -1.5456629e-03\n",
      "  1.5109634e-03  1.7900408e-03  7.8175711e-03 -9.5101865e-03\n",
      " -2.0553112e-04  3.4691966e-03 -9.3897223e-04  8.3817719e-03\n",
      "  9.0107834e-03  6.5365066e-03 -7.1162102e-04  7.7104042e-03\n",
      " -8.5343346e-03  3.2071066e-03 -4.6379971e-03 -5.0889552e-03\n",
      "  3.5896183e-03  5.3703394e-03  7.7695143e-03 -5.7665063e-03\n",
      "  7.4333609e-03  6.6254963e-03 -3.7098003e-03 -8.7456414e-03\n",
      "  5.4374672e-03  6.5097557e-03 -7.8755023e-04 -6.7098560e-03\n",
      " -7.0859254e-03 -2.4970602e-03  5.1432536e-03 -3.6652375e-03\n",
      " -9.3700597e-03  3.8267397e-03  4.8844791e-03 -6.4285635e-03\n",
      "  1.2085581e-03 -2.0748770e-03  2.4403334e-05 -9.8835090e-03\n",
      "  2.6920044e-03 -4.7501065e-03  1.0876465e-03 -1.5762246e-03\n",
      "  2.1966731e-03 -7.8815762e-03 -2.7171839e-03  2.6631986e-03\n",
      "  5.3466819e-03 -2.3915148e-03 -9.5100943e-03  4.5058788e-03]\n"
     ]
    }
   ],
   "source": [
    "# Example: Get word embedding for 'machine'\n",
    "word_embedding = model.wv['machine']\n",
    "print(\"Word embedding for 'machine':\", word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85aed49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
